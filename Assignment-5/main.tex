\documentclass[journal,12pt,twocolumn]{IEEEtran}

\usepackage{setspace}
\usepackage{gensymb}
\singlespacing
\usepackage[cmex10]{amsmath}

\usepackage{amsthm}

\usepackage{mathrsfs}
\usepackage{txfonts}
\usepackage{stfloats}
\usepackage{bm}
\usepackage{cite}
\usepackage{cases}
\usepackage{subfig}

\usepackage{longtable}
\usepackage{multirow}

\usepackage{enumitem}
\usepackage{mathtools}
\usepackage{steinmetz}
\usepackage{tikz}
\usepackage{circuitikz}
\usepackage{verbatim}
\usepackage{tfrupee}
\usepackage[breaklinks=true]{hyperref}
\usepackage{graphicx}
\usepackage{tkz-euclide}

\usetikzlibrary{calc,math}
\usepackage{listings}
    \usepackage{color}                                            %%
    \usepackage{array}                                            %%
    \usepackage{longtable}                                        %%
    \usepackage{calc}                                             %%
    \usepackage{multirow}                                         %%
    \usepackage{hhline}                                           %%
    \usepackage{ifthen}                                           %%
    \usepackage{lscape}     
\usepackage{multicol}
\usepackage{chngcntr}

\DeclareMathOperator*{\Res}{Res}

\renewcommand\thesection{\arabic{section}}
\renewcommand\thesubsection{\thesection.\arabic{subsection}}
\renewcommand\thesubsubsection{\thesubsection.\arabic{subsubsection}}

\renewcommand\thesectiondis{\arabic{section}}
\renewcommand\thesubsectiondis{\thesectiondis.\arabic{subsection}}
\renewcommand\thesubsubsectiondis{\thesubsectiondis.\arabic{subsubsection}}


\hyphenation{op-tical net-works semi-conduc-tor}
\def\inputGnumericTable{}                                 %%

\lstset{
%language=C,
frame=single, 
breaklines=true,
columns=fullflexible
}
\begin{document}


\newtheorem{theorem}{Theorem}[section]
\newtheorem{problem}{Problem}
\newtheorem{proposition}{Proposition}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{example}{Example}[section]
\newtheorem{definition}[problem]{Definition}

\newcommand{\BEQA}{\begin{eqnarray}}
\newcommand{\EEQA}{\end{eqnarray}}
\newcommand{\define}{\stackrel{\triangle}{=}}
\bibliographystyle{IEEEtran}
\raggedbottom
\setlength{\parindent}{0pt}
\providecommand{\mbf}{\mathbf}
\providecommand{\pr}[1]{\ensuremath{\Pr\left(#1\right)}}
\providecommand{\qfunc}[1]{\ensuremath{Q\left(#1\right)}}
\providecommand{\sbrak}[1]{\ensuremath{{}\left[#1\right]}}
\providecommand{\lsbrak}[1]{\ensuremath{{}\left[#1\right.}}
\providecommand{\rsbrak}[1]{\ensuremath{{}\left.#1\right]}}
\providecommand{\brak}[1]{\ensuremath{\left(#1\right)}}
\providecommand{\lbrak}[1]{\ensuremath{\left(#1\right.}}
\providecommand{\rbrak}[1]{\ensuremath{\left.#1\right)}}
\providecommand{\cbrak}[1]{\ensuremath{\left\{#1\right\}}}
\providecommand{\lcbrak}[1]{\ensuremath{\left\{#1\right.}}
\providecommand{\rcbrak}[1]{\ensuremath{\left.#1\right\}}}
\newcommand*{\permcomb}[4][0mu]{{{}^{#3}\mkern#1#2_{#4}}}
\newcommand*{\perm}[1][-3mu]{\permcomb[#1]{P}}
\newcommand*{\comb}[1][-1mu]{\permcomb[#1]{C}}
\theoremstyle{remark}
\newtheorem{rem}{Remark}
\newcommand{\sgn}{\mathop{\mathrm{sgn}}}
\providecommand{\abs}[1]{\left\vert#1\right\vert}
\providecommand{\res}[1]{\Res\displaylimits_{#1}} 
\providecommand{\norm}[1]{\left\lVert#1\right\rVert}
%\providecommand{\norm}[1]{\lVert#1\rVert}
\providecommand{\mtx}[1]{\mathbf{#1}}
\providecommand{\mean}[1]{E\left[ #1 \right]}
\providecommand{\fourier}{\overset{\mathcal{F}}{ \rightleftharpoons}}
%\providecommand{\hilbert}{\overset{\mathcal{H}}{ \rightleftharpoons}}
\providecommand{\system}{\overset{\mathcal{H}}{ \longleftrightarrow}}
	%\newcommand{\solution}[2]{\textbf{Solution:}{#1}}
\newcommand{\solution}{\noindent \textbf{Solution: }}
\newcommand{\cosec}{\,\text{cosec}\,}
\providecommand{\dec}[2]{\ensuremath{\overset{#1}{\underset{#2}{\gtrless}}}}
\newcommand{\myvec}[1]{\ensuremath{\begin{pmatrix}#1\end{pmatrix}}}
\newcommand{\mydet}[1]{\ensuremath{}}
\numberwithin{equation}{subsection}
\makeatletter
\@addtoreset{figure}{problem}
\makeatother
\let\StandardTheFigure\thefigure
\let\vec\mathbf
\renewcommand{\thefigure}{\theproblem}
\def\putbox#1#2#3{\makebox[0in][l]{\makebox[#1][l]{}\raisebox{\baselineskip}[0in][0in]{\raisebox{#2}[0in][0in]{#3}}}}
     \def\rightbox#1{\makebox[0in][r]{#1}}
     \def\centbox#1{\makebox[0in]{#1}}
     \def\topbox#1{\raisebox{-\baselineskip}[0in][0in]{#1}}
     \def\midbox#1{\raisebox{-0.5\baselineskip}[0in][0in]{#1}}
\vspace{3cm}
\title{Assignment 5}
\author{Vaibhav Chhabra \\ AI20BTECH11022}
\maketitle
\newpage
\bigskip
\renewcommand{\thefigure}{\theenumi}
\renewcommand{\thetable}{\theenumi}
Download all latex codes from 
\begin{lstlisting}
https://github.com/vaibhavchhabra25/AI1103-course/blob/main/Assignment-5/main.tex
\end{lstlisting}
\section{Problem}
(UGC/MATH 2018 (June set-a)-Q.106) Let $\{X_i\}_{i \geq 1}$ be a sequence of i.i.d. random variables with $E(X_i)=0$ and $V(X_i)=1$. Which of the following are true?
\vspace{0.2cm}
\begin{enumerate}
    \item $\dfrac{1}{n} \sum_{i=1}^n X_i^2 \to 0$ in probability \vspace{0.2cm}
    \item $\dfrac{1}{n^{3/4}} \sum_{i=1}^n X_i \to 0$ in probability \vspace{0.2cm}
    \item $\dfrac{1}{n^{1/2}} \sum_{i=1}^n X_i \to 0$ in probability \vspace{0.2cm}
    \item $\dfrac{1}{n} \sum_{i=1}^n X_i^2 \to 1$ in probability
\end{enumerate}
\section{Solution}
\begin{definition}
    (Convergence in probability)\\
    Let $X1, X2$, . . . be an infinite sequence of random variables, and let $Y$ be another random variable. Then the sequence $\{X_n\}$ converges in probability to $Y$, if for all $\epsilon >0$, 
    \begin{align}
        \lim_{n \to \infty}\pr{|X_n-Y|\geq \epsilon}=0
    \end{align}
And we write as $n \to \infty$, $X_n \to Y$ in probability.
\end{definition}
\begin{theorem}
    (Strong Law of Large Numbers)\\
    Let $X_1, X_2, \cdot \cdot \cdot$ be a sequence of i.i.d. random variables, each having finite mean $E(X_i)$. Then for any $\epsilon >0$,
    \begin{align}
        \lim_{n \to \infty}\pr{\left|\dfrac{1}{n}\sum_{i=1}^nX_i - E(X_i)\right|\geq \epsilon}=0
    \end{align}
    Or, $\dfrac{1}{n}\sum_{i=1}^nX_i$ converges in probability to $E(X_i)$.
\end{theorem}
Given,
\begin{align} 
    E(X_i)&=0 
    \label{a}\\
    V(X_i)&=1
    \label{b}
\end{align}
Also, we know that,
\begin{align}
    E(X_i^2)=V(X_i)+(E(X_i))^2
\end{align}
Putting given values, we get,
\begin{align} \label{c}
    E(X_i^2)&=1+0^2=1 \\
    \implies E(X_i^2)&=1
\end{align}
So, $E(X_i^2)$ is finite.\\
As $\{X_i\}$ is sequence of i.i.d. random variables, it follows the following conditions $\forall x,x_i \in \mathbb{R}$:
\begin{enumerate}
    \item $\pr{X_1 \leq x}=\pr{X_k \leq x} \ \forall k \in \{1,2,3 \cdot \cdot     \cdot n\}$
    \item $\pr{X_1 \leq x_1, X_2 \leq x_2 \cdot \cdot \cdot X_n \leq x_n } =\\
        \pr{X_1 \leq x_1} \cdot \pr{X_2 \leq x_2} \cdot \cdot \cdot \pr{X_n \leq x_n}$
\end{enumerate}
We can rewrite (1) as
\begin{align}
    &\pr{X_1^2 \leq x^2}=\pr{X_k^2 \leq x^2}
\end{align}
Putting $x^2=y$, we get,
\begin{align} \label{d}
    \pr{X_1^2 \leq y}=\pr{X_k^2 \leq y}
\end{align}
Also, we can rewrite (2) as
\begin{align}
    &\pr{X_1^2 \leq x_1^2, X_2^2 \leq x_2^2 \cdot \cdot \cdot X_n^2 \leq x_n^2 } = \nonumber \\
    &\pr{X_1^2 \leq x_1^2} \cdot \pr{X_2^2 \leq x_2^2} \cdot \cdot \cdot \pr{X_n^2 \leq x_n^2}
\end{align}
Putting $x_i^2=y_i$, we get,
\begin{align} \label{e}
    &\pr{X_1^2 \leq y_1, X_2^2 \leq y_2 \cdot \cdot \cdot X_n^2 \leq y_n } = \nonumber \\
    &\pr{X_1^2 \leq y_1} \cdot \pr{X_2^2 \leq y_2} \cdot \cdot \cdot \pr{X_n^2 \leq y_n}
\end{align}
By \eqref{d} and \eqref{e}, $\{X_i^2\}$ must also be a sequence of i.i.d. random variables.\\
So, we can apply S.L.L.N. to this sequence.\\
Then, $\dfrac{1}{n}\sum_{i=1}^nX_i^2$ converges in probability to $E(X_i^2)$.\\
Or, $\dfrac{1}{n}\sum_{i=1}^nX_i^2 \to 1$ in probability.\\
Thus, option 1 is wrong and option 4 is correct.
\vspace{0.3cm}\\
Now, we define
\begin{align}
    Y_n=\dfrac{1}{n^{3/4}}\sum_{i=1}^nX_i
\end{align}
Then,
\begin{align}
    E(Y_n) &= \dfrac{1}{n^{3/4}}E\brak{\sum_{i=1}^nX_i} \\
    \implies E(Y_n) &= \dfrac{1}{n^{3/4}}\brak{E(X_1)+E(X_2)+ \cdot \cdot \cdot +E(X_n)}
\end{align}
Using \eqref{a}
\begin{align}
    E(Y_n) &= \dfrac{1}{n^{3/4}}\brak{0} =0
\end{align}
Now,
\begin{align}
    V(Y_n) &= V\brak{\dfrac{1}{n^{3/4}}\sum_{i=1}^nX_i} \\
    \implies V(Y_n) &= \dfrac{1}{n^{3/2}}V\brak{X_1+X_2+ \cdot \cdot \cdot +X_n}
\end{align}
As $X_1, X_2, \cdot \cdot \cdot X_n$ are independent of each other,
\begin{align}
    V(Y_n) &= \dfrac{1}{n^{3/2}}\brak{V(X_1)+V(X_2)+ \cdot \cdot \cdot +V(X_n)}
\end{align}
Using \eqref{b}
\begin{align}
    V(Y_n)=\dfrac{1}{n^{3/2}}\brak{1+1+\cdot \cdot \cdot+1}=\dfrac{1}{n^{3/2}}\times n=\dfrac{1}{n^{1/2}}
\end{align}
Now for any $\epsilon>0$, consider the probability
\begin{align}
    \pr{|Y_n-0|\geq \epsilon}=\pr{|Y_n-E(Y_n)|\geq \epsilon}
\end{align}
Applying Chebyschev's inequality here, we get,
\begin{align}
    \pr{|Y_n-0|\geq \epsilon} \leq \dfrac{V(Y_n)}{\epsilon^2} = \dfrac{1}{n^{1/2}\epsilon^2}
\end{align}
So,
\begin{align}
    \lim_{n \to \infty}\pr{|Y_n-0|\geq \epsilon} \leq \lim_{n \to \infty }\dfrac{1}{n^{1/2}\epsilon^2}=0\\
    \implies \lim_{n \to \infty}\pr{\left | \dfrac{1}{n^{3/4}}\sum_{i=1}^nX_i - 0 \right|\geq \epsilon}=0
\end{align}
So, $\dfrac{1}{n^{3/4}}\sum_{i=1}^nX_i \to 0$ in probability.\\
Thus, option 2 is also correct.\\
So the answer must be options 2,4.
\end{document}
